{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of BIS Intro to AI - Hello Wolrd.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtdearing/BIS-intro-to-AI/blob/master/BIS_Intro_to_AI_Hello_Wolrd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaCF4oM2KteO",
        "colab_type": "text"
      },
      "source": [
        "# A \"Hello World\" introduction to doing machine learning\n",
        "## for BIS at Argonne National Laboratory.\n",
        "\n",
        "### *Matthew T. Dearing, 2019*\n",
        "\n",
        "> Adapted from [Jason Brownlee](https://machinelearningmastery.com/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYuyjR1eJ-E-",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/7/76/Purple_iris_flower.JPG/320px-Purple_iris_flower.JPG)\n",
        "\n",
        "The **Iris dataset** was used in R.A. Fisher's classic 1936 paper, [The Use of Multiple Measurements in Taxonomic Problems](http://rcs.chemometrics.ru/Tutorials/classification/Fisher.pdf), and can also be found in the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/).\n",
        "\n",
        "It includes three iris species with 50 samples each as well as some properties about each flower. One flower species is linearly separable from the other two, but the other two are not linearly separable from each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouhyR2mELUt5",
        "colab_type": "text"
      },
      "source": [
        "## **The Iris Dataset**\n",
        "# 1. Load the dataset.\n",
        "# 2. Summarize the dataset.\n",
        "# 3. Visualize the dataset.\n",
        "# 4. Evaluate some algorithms.\n",
        "# 5. Making some predictions.\n",
        "\n",
        "We'll use 5 important libraries:\n",
        "\n",
        "*   scipy https://www.scipy.org\n",
        "*   numpy https://numpy.org/\n",
        "*   matplotlib https://matplotlib.org/\n",
        "*   pandas https://pandas.pydata.org/\n",
        "*   sklearn https://scikit-learn.org/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5aQrvLX157K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "print('Python: {}'.format(sys.version))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoLMYqmr5rgK",
        "colab_type": "text"
      },
      "source": [
        "(These print statements are not necessary... they are just to get your fingers wet with a bit Python code and see some output. The *import statements* below, however, are critical.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iFo99-Q2Uf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "print('scipy: {}'.format(scipy.__version__))\n",
        "import numpy\n",
        "print('numpy: {}'.format(numpy.__version__))\n",
        "import matplotlib\n",
        "print('matplotlib: {}'.format(matplotlib.__version__))\n",
        "import pandas\n",
        "print('pandas: {}'.format(pandas.__version__))\n",
        "import sklearn\n",
        "print('sklearn: {}'.format(sklearn.__version__))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33Tuba9S3HIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load all the modules, functions, and objects we will use:\n",
        "\n",
        "# pandas for processing our data and a bit of visualization:\n",
        "from pandas import read_csv\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "# matplotlib for statistical visualizations:\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# sklearn to bring in all the machine learning fun:\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC9N2Yue25mP",
        "colab_type": "text"
      },
      "source": [
        "Now, we will load the Iris dataset, which contains (only) 150 observations of iris flowers. \n",
        "\n",
        "There are four columns of measurements in centimeters with a fifth column designating the *species of the flower*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIkDyBeh3lWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load in the dataset (thanks, Internet!)\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\n",
        "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class'] # To set labels to the column headers\n",
        "dataset = read_csv(url, names=names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcXAV9_O3sUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shape - get a high level picture of your data\n",
        "dataset.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v5K7nO03vep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Head - take a quick peak at the first X rows of data.\n",
        "dataset.head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wTZ6z3C31f5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Describe your dataset with some basic statistics\n",
        "dataset.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "690eChx337lL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class distribution - run a count based on one of the columns\n",
        "dataset.groupby('class').size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKfO63HB4Dqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize the statistics of your data with box and whisker plots - to look at medians (middle values), means (averages), and spreads in your data.\n",
        "dataset.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecQLtxXs4RtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Histograms - to count the distributions of each feature\n",
        "dataset.hist()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBoHCmTO4eMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scatter plot matrix - how are the features correlated? or, how do they interact?\n",
        "\n",
        "# Diagonal groupings suggest a predictable relationship between two features. \n",
        "scatter_matrix(dataset)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxA073Lt7Fai",
        "colab_type": "text"
      },
      "source": [
        "We have first tried to understand our data.\n",
        "\n",
        "So, now we can try to develop a machine model of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6WNRiJN4uel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split up your data into training and testing (or validation) datasets.\n",
        "# We'll build the model with the training sub-set and test the performance of the model on the test sub-set.\n",
        "array = dataset.values\n",
        "X = array[:,0:4] # Separate out just the features into a set\n",
        "Y = array[:,4] # Separate out just the labels into another set\n",
        "\n",
        "# Automatically split out the training and validation sets, randomly selected into 20% for testing, 80% for training:\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.20, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdk-qUrO5SfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Spot check multiple algorithms -- remember, No Free Lunch!\n",
        "\n",
        "# So, we'll build a model using each of these methods in a loop and compare the results based on accuracy at the same time:\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC(gamma='auto')))\n",
        "\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "\t# K-fold (10) Cross validation to score each model. This randomly splits the data up an runs the algorithms on each to check performance.\n",
        "\tkfold = StratifiedKFold(n_splits=10, random_state=1)\n",
        "\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std())) # The average accuracy and the standard deviation."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vscm_aoS6HCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compare Algorithms\n",
        "pyplot.boxplot(results, labels=names)\n",
        "pyplot.title('Algorithm Comparison')\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZfrzGc56Tmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make predictions on validation dataset using the model that seemed to do the best\n",
        "model = SVC(gamma='auto')\n",
        "model.fit(X_train, Y_train)\n",
        "predictions = model.predict(X_validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAFd7b206YWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate predictions\n",
        "# Accuracy := the ratio of the number of correct predictions to the total number of input samples. \n",
        "accuracy_score(Y_validation, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWN8v9UiINAc",
        "colab_type": "text"
      },
      "source": [
        "But, accuracy alone isn't enough to be sure you have a good model (it depends on the data you are working with)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aysbQBBjQpXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a table that compares the success of each prediction, specifying True Positives, True Negatives, False Positives, and False Negatives.\n",
        "confusion_matrix(Y_validation, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4KLO3RGKgYY",
        "colab_type": "text"
      },
      "source": [
        "**Precision** :=  The number of correct positive results divided by the number of positive results predicted by the classifier.\n",
        "\n",
        "**Recall** := The number of correct positive results divided by the number of all relevant samples (all samples that should have been identified as positive).\n",
        "\n",
        "**F1 Score** := the harmonic mean (and average of rates) of precision and recall, between [0,1] that designates how precise the classifer is (how many it gets right) and how robust it is (it doesn't get too many wrong)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FhVNVDLQCuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(Y_validation, predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}